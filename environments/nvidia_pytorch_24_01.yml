# source: https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-01.html

name: nvidia_pytorch_24_01
channels:
  - nvidia
  - pytorch
  - conda-forge
  - defaults

dependencies:
  # Base
  - python=3.10                 # PyTorch container uses Python 3.10 :contentReference[oaicite:1]{index=1}
  - pip

  # CUDA / GPU stack
  - cuda-toolkit=12.3.2           # container is based on CUDA 12.3.2 :contentReference[oaicite:2]{index=2}
  - cudnn=8.9.7.29               # cuDNN version in container :contentReference[oaicite:3]{index=3}
  - nccl                          # for distributed GPU (if needed)

  # PyTorch & GPU integration
  - pytorch=2.2.0a0              # matches the PyTorch version in the container :contentReference[oaicite:4]{index=4}
  - pytorch-cuda=12.3             # ensures GPU-enabled PyTorch for CUDA 12.3
  - torchvision                   # match automatically with PyTorch build
  - torchaudio                    # optional (if you need audio)
  - torchtext                      # optional
  - torchdata                     # optional

  # Additional NVIDIA / ecosystem libraries (optional, depending on your use case)
  - tensorrt=8.6.1.6               # TensorRT in container spec :contentReference[oaicite:5]{index=5}
  - torch-tensorrt=2.2.0a0         # matching version in container :contentReference[oaicite:6]{index=6}
  - dali=1.33                      # NVIDIA DALI version in container :contentReference[oaicite:7]{index=7}
  - transformerengine=1.2.1        # included in container :contentReference[oaicite:8]{index=8}

  # Standard ML / data packages
  - numpy
  - scipy
  - pandas
  - scikit-learn
  - matplotlib
  - jupyterlab

  # Pip-only dependencies your project needs
  #- pip:
  #    - your_other_python_packages
